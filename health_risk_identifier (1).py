# -*- coding: utf-8 -*-
"""Health_Risk_Identifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mltwZTryHQQxhXye8i0u2J7kG8gkuSK0
"""

!pip install -U crewai litellm pandas streamlit pyngrok

import os
import json
import pandas as pd
from getpass import getpass
from crewai import Agent, Task, Crew, Process, LLM
import streamlit as st

if "GROQ_API_KEY" not in os.environ:
    os.environ["GROQ_API_KEY"] = getpass("Enter your Groq API Key: ")

llm = LLM(model="groq/llama-3.1-8b-instant",
    temperature=0.2)

collector = Agent(
    role="Patient Collector",
    goal="Organize patient vitals",
    backstory="Expert healthcare data assistant",
    llm=llm,
    verbose=True
)

doctor = Agent(
    role="Doctor AI",
    goal="Analyze patient data and identify health risks",
    backstory="Clinical AI assistant",
    llm=llm,
    verbose=True
)

def analyze_patients(dataframe):
    all_results = []

    # Fill missing values once instead of every loop
    dataframe = dataframe.fillna("Not Provided")

    # Loop through patients
    for _, row in dataframe.iterrows():

        patient_info = ", ".join(
            f"{col}: {row[col]}" for col in dataframe.columns
        )

        collect_vitals_task = Task(
            description=(
                f"Organize and structure patient medical data from: "
                f"{patient_info}. Use only provided data and do not invent details."
            ),
            agent=collector,
            expected_output="Structured patient medical summary."
        )

        analyze_health_task = Task(
            description=(
                "Using the structured patient information from the previous step, "
                "identify health risks and provide practical preliminary advice "
                "without inventing any medical data."
            ),
            agent=doctor,
            expected_output="Health risk analysis with reasoning and advice."
        )

        crew = Crew(
            agents=[collector, doctor],
            tasks=[collect_vitals_task, analyze_health_task],
            process=Process.sequential,
        )

        result = crew.kickoff()
        all_results.append(result)

    return all_results

st.title("Health Risk Identifier App")

uploaded_file = st.file_uploader("Upload Health Risk Dataset", type="csv")

if uploaded_file is not None:
    try:
        # Read dataset
        df = pd.read_csv(uploaded_file)

        st.subheader("Uploaded Patient Data")
        st.dataframe(df)

        # Run analysis with spinner
        with st.spinner("Analyzing health risks..."):
            result = analyze_patients(df)

        st.subheader("Analysis Results")

        # Show patient results
        for i, res in enumerate(result):
            st.markdown(f"### Patient {i+1}")
            st.write(res)

        # Optional JSON display
        st.subheader("Full Results (JSON View)")
        st.json(result)

        # Download results option
        st.download_button(
            label="Download Results",
            data=str(result),
            file_name="health_risk_results.txt",
            mime="text/plain"
        )

    except Exception as e:
        st.error(f"Error processing file: {e}")

from pyngrok import ngrok
from getpass import getpass
# Stop previous tunnels safely
try:
    ngrok.kill()
except:
    pass

# Streamlit default port
port = 8501

# Set ngrok auth token
NGROK_AUTH_TOKEN = getpass("Enter your ngrok Auth Token: ")
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# Create public tunnel
public_url = ngrok.connect(port)

print("âœ… Streamlit app is live at:")
print(public_url)

from pyngrok import ngrok

ngrok.kill()

public_url = ngrok.connect(8501)
print(public_url.public_url)